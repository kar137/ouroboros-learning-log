{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e510f9",
   "metadata": {},
   "source": [
    "# PyTorch Tensor Foundations\n",
    "Short notes I wrote while stepping through tensor basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24c2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35c146",
   "metadata": {},
   "source": [
    "### Device check\n",
    "Keep everything on CPU unless a GPU is actually available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b2447c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29730b6",
   "metadata": {},
   "source": [
    "### Building tensors\n",
    "Start from plain data, NumPy, and other tensors to see how types carry over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86908677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e9354",
   "metadata": {},
   "source": [
    "From NumPy to torch (shape and dtype stay the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2d05fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2.],\n",
       "         [3., 4.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data, dtype=np.float32)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np, x_np.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260c432",
   "metadata": {},
   "source": [
    "Clone an existing tensor and override dtype when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66af8d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1],\n",
       "         [1, 1]]),\n",
       " tensor([[0.1447, 0.8444],\n",
       "         [0.1770, 0.5319]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float32)\n",
    "x_ones, x_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f72ff",
   "metadata": {},
   "source": [
    "Random and constant initializers with explicit shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618aa0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6151, 0.2206, 0.1002],\n",
       "         [0.0292, 0.8685, 0.2241]]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "rand_tensor, ones_tensor, zeros_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ce7b4",
   "metadata": {},
   "source": [
    "### Tensor attributes\n",
    "Shape, dtype, and device show up as properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f93b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4, device=device)\n",
    "tensor.shape, tensor.dtype, tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b580782",
   "metadata": {},
   "source": [
    "### Basic ops\n",
    "Most NumPy habits carry over: slicing, joining, math, and in-place operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312edba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.]]),\n",
       " tensor([1., 0., 1., 1.]),\n",
       " tensor([1., 1., 1., 1.]),\n",
       " tensor([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones((4, 4))\n",
    "first_row = tensor[0]\n",
    "first_col = tensor[:, 0]\n",
    "last_col = tensor[:, -1]\n",
    "tensor[:, 1] = 0\n",
    "tensor, first_row, first_col, last_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b705d321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor], dim=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6b4dbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.]]),\n",
       " tensor([[1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tensor @ tensor.T\n",
    "z = tensor * tensor\n",
    "y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe3ab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12.), 12.0, float)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "agg, agg_item, type(agg_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c6a31",
   "metadata": {},
   "source": [
    "In-place ops (watch out when autograd is on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa3dc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.add_(5)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81addde0",
   "metadata": {},
   "source": [
    "### Bridge with NumPy\n",
    "CPU tensors share memory with NumPy arrays; edits echo both ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95ae6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "n = t.numpy()\n",
    "t, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785acfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2.]), array([2., 2., 2., 2., 2.], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.add_(1)\n",
    "t, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52e85bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 3., 3., 3., 3.], dtype=torch.float64),\n",
       " array([3., 3., 3., 3., 3.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2 = np.ones(5)\n",
    "t2 = torch.from_numpy(n2)\n",
    "np.add(n2, 2, out=n2)\n",
    "t2, n2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
